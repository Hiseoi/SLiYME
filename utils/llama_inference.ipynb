{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.12.2: Fast Llama patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"checkpoint-300\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Generate a song lyric line which will come next. You should follow Syllable structure in Next lyric line like Context.\n",
    "\n",
    "### Input:\n",
    "Context:\n",
    "{context_lines}\n",
    "Next lyric line: {processed_line}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "# 데이터를 정의\n",
    "instruction = \"Generate a single lyric line that continues the Context.\"\n",
    "context_lines = \"\"\"\\n(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL]) Get her name and get her number\\n\n",
    "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL]) Find out all of the things\\n\n",
    "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL]) that we have in common\"\"\"\n",
    "processed_line = \"\\n(Syllable Structure: [SYL][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL][SYL][SYL])\"\n",
    "response = \"\"  # 빈 값으로 설정 (생성용)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "Generate a song lyric line which will come next. You should follow Syllable structure in Next lyric line like Context.\n",
      "\n",
      "### Input:\n",
      "Context:\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL]) Get her name and get her number\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL]) Find out all of the things\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL]) that we have in common\n",
      "Next lyric line: \n",
      "(Syllable Structure: [SYL][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL][SYL][SYL])\n",
      "\n",
      "### Response:\n",
      "And I don't wanna know\n",
      "        <|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    lyric_prompt.format(\n",
    "        context_lines=context_lines,\n",
    "        processed_line=processed_line,\n",
    "        response=response\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Generate a song lyric line which will come next. You should follow Syllable structure in Next lyric line like Context.\n",
    "\n",
    "### Input:\n",
    "Context:\n",
    "{context_lines}\n",
    "Next lyric line: {processed_line}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "# 데이터를 정의\n",
    "instruction = \"Generate a single lyric line that continues the Context.\"\n",
    "context_lines = \"\"\"\\n(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SYL]) melt like butter\\n\n",
    "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SYL]) Can't get enough\\n\n",
    "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL]) and I love the way that you taste\"\"\"\n",
    "processed_line = \"\\n(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL])\"\n",
    "response = \"\"  # 빈 값으로 설정 (생성용)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "Generate a song lyric line which will come next. You should follow Syllable structure in Next lyric line like Context.\n",
      "\n",
      "### Input:\n",
      "Context:\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SYL]) melt like butter\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SYL]) Can't get enough\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL]) and I love the way that you taste\n",
      "Next lyric line: \n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL])\n",
      "\n",
      "### Response:\n",
      "You're my addiction and I'm addicted\n",
      "        <|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    lyric_prompt.format(\n",
    "        context_lines=context_lines,\n",
    "        processed_line=processed_line,\n",
    "        response=response\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Generate a song lyric line which will come next. You should follow Syllable structure in Next lyric line like Context.\n",
    "\n",
    "### Input:\n",
    "Context:\n",
    "{context_lines}\n",
    "Next lyric line: {processed_line}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "# 데이터를 정의\n",
    "instruction = \"Generate a single lyric line that continues the Context.\"\n",
    "context_lines = \"\"\"\\n(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL]) You could be my teacher\\n\n",
    "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL]) And I could be your rose\\n\n",
    "(Syllable Structure: [SYL][SYL]) Darling\"\"\"\n",
    "processed_line = \"\\n(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL])\"\n",
    "response = \"\"  # 빈 값으로 설정 (생성용)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "Generate a song lyric line which will come next. You should follow Syllable structure in Next lyric line like Context.\n",
      "\n",
      "### Input:\n",
      "Context:\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL]) You could be my teacher\n",
      "\n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL]) And I could be your rose\n",
      "\n",
      "(Syllable Structure: [SYL][SYL]) Darling\n",
      "Next lyric line: \n",
      "(Syllable Structure: [SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SEP][SYL][SYL])\n",
      "\n",
      "### Response:\n",
      "I know that I'm not the one for you\n",
      "        <|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    lyric_prompt.format(\n",
    "        context_lines=context_lines,\n",
    "        processed_line=processed_line,\n",
    "        response=response\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
